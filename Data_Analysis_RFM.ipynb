{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCcwDpZ2kc9D"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "OuSVf2rxkjvs",
        "outputId": "c21a4693-75e5-4563-d60f-5766d68b4aa7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-867e4117-42b3-4fa3-acc1-f7e927720e32\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-867e4117-42b3-4fa3-acc1-f7e927720e32\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRcQpHt0-IL-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "df = pd.read_csv('data.csv', encoding='latin-1')\n",
        "\n",
        "# Displaying the first few rows of the DataFrame\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLdbNh53-IWS"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJPgG8QuEpej"
      },
      "outputs": [],
      "source": [
        "df.describe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvwtTqOz_xqb"
      },
      "source": [
        "# **EDA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3cbTnWO-IdV"
      },
      "outputs": [],
      "source": [
        "# Basic overview\n",
        "print(df.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ErxY1N36-IkE"
      },
      "outputs": [],
      "source": [
        "# checking if there are any Missing values\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvcWer1MlHIA"
      },
      "outputs": [],
      "source": [
        "#checkinging missing values description(Products)\n",
        "# Displaying rows with missing descriptions\n",
        "missing_desc = df[df['Description'].isnull()]\n",
        "print(missing_desc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrAAcPpOvUYN"
      },
      "source": [
        "We are having 1454 null values in  Description column so we have to deal with it before we proceed further"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1waXr4UAUL1"
      },
      "outputs": [],
      "source": [
        "# Replace missing descriptions with \"not mentioned\" and inpulus will make this change in our original DataFrame\n",
        "df['Description'].fillna('not mentioned', inplace=True)\n",
        "\n",
        "# Verify the changes\n",
        "print(df.info())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnEdalUlAs_a"
      },
      "outputs": [],
      "source": [
        "# for checking rows with missing CustomerID so we can work on that, like how to manage these values\n",
        "missing_customer_id = df[df['CustomerID'].isnull()]\n",
        "print(missing_customer_id)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQk0WyDaBABC"
      },
      "outputs": [],
      "source": [
        "#There are few non nomeric values in our invoce column\n",
        "# Convert 'InvoiceNo' to numeric, setting non-numeric values to NaN\n",
        "numeric_invoice = pd.to_numeric(df['InvoiceNo'], errors='coerce')\n",
        "# Count the total non-numeric values\n",
        "non_numeric_count = numeric_invoice.isna().sum()\n",
        "# Displaying the result\n",
        "print(f'Total non-numeric values in InvoiceNo: {non_numeric_count}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRlIdOwmBW6f"
      },
      "outputs": [],
      "source": [
        "# Convert 'InvoiceNo' to numeric, setting non-numeric values to (-1) so we can perform numercal procedures\n",
        "# we have used (errors='coerce') to avoid from error incase there is some non numeric value in our data whic can cause Nan (not a number) error\n",
        "df['InvoiceNo'] = pd.to_numeric(df['InvoiceNo'], errors='coerce').fillna(-1).astype(int)\n",
        "\n",
        "# Verify the changes\n",
        "print(df.info())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StJJoRqLyhBm"
      },
      "source": [
        "Now we have no more null values in our data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RR1RTJL7C4yz"
      },
      "outputs": [],
      "source": [
        "# Replace missing CustomerID with InvoiceNo + 1 so we can fill the gap\n",
        "df['CustomerID'].fillna(df['InvoiceNo'] + 1, inplace=True)\n",
        "\n",
        "# Verify the changes\n",
        "print(df.info())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_i_6wy1DEqj"
      },
      "outputs": [],
      "source": [
        "# Convert 'InvoiceDate' to datetime\n",
        "# we have used (errors='coerce') to avoid from error incase there is some non numeric value in our data whic can cause Nan (not a number) error\n",
        "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'], errors='coerce')\n",
        "\n",
        "# Verify the changes\n",
        "print(df.info())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5MVxu-gDCyo"
      },
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loFnN0OZDfGd"
      },
      "outputs": [],
      "source": [
        "# Convert 'InvoiceDate' to datetime and extract the date\n",
        "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate']).dt.date\n",
        "\n",
        "# Verify the changes\n",
        "print(df.info())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2LhWC8Bz4TR"
      },
      "source": [
        "we still have invoice date column in object data type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSkY2n7JDlUd"
      },
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9pXZe8jD_YO"
      },
      "outputs": [],
      "source": [
        "# Convert 'InvoiceDate' to datetime\n",
        "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
        "\n",
        "# Verify the changes\n",
        "print(df.dtypes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPshIc5EmIJu"
      },
      "outputs": [],
      "source": [
        "# Print the 'InvoiceDate' column\n",
        "print(df['InvoiceDate'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVGCZFuRnanH"
      },
      "source": [
        "# **Recency**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRKTl8fCmqvC"
      },
      "outputs": [],
      "source": [
        "# Find the maximum date in the entire dataset\n",
        "max_date_all = df['InvoiceDate'].max()\n",
        "print(max_date_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4L66qlpzI5L3"
      },
      "outputs": [],
      "source": [
        "# ReAssigning column names in the original DataFrame\n",
        "df.columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']\n",
        "\n",
        "# Creating a new DataFrame with updated column names\n",
        "#making new data frame with Maxdate heading\n",
        "max_date_df = df.groupby('CustomerID')['InvoiceDate'].max().reset_index(name='MaxDate')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgPQFnxvne-7"
      },
      "outputs": [],
      "source": [
        "# Calculating Recency based on the maximum date for each customer\n",
        "max_date_df = df.groupby('CustomerID')['InvoiceDate'].max().reset_index()\n",
        "max_date_df.columns = ['CustomerID', 'MaxDate']\n",
        "print(max_date_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXzkS-3FJqIV"
      },
      "outputs": [],
      "source": [
        "# Merge max_date_df into the original DataFrame df\n",
        "df = pd.merge(df, max_date_df, on='CustomerID', how='left')\n",
        "\n",
        "# Calculating Recency using the maximum date from the entire dataset\n",
        "df['Recency'] = (max_date_all - df['MaxDate']).dt.days\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMsNdMfVI-V5"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6avANTroPZu"
      },
      "outputs": [],
      "source": [
        "# Calculating Recency using the maximum date from the entire dataset\n",
        "df['Recency'] = (max_date_all - df['MaxDate']).dt.days\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTZbEYKKobkn"
      },
      "outputs": [],
      "source": [
        "# Drop unnecessary MaxDate column and saving the data frame\n",
        "df.drop(['MaxDate'], axis=1, inplace=True)\n",
        "\n",
        "# Displaying the updated DataFrame\n",
        "print(\"\\nRecency Calculation using Maximum Date in the Entire Dataset\")\n",
        "print(df[['CustomerID', 'Recency']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDADUKfOo1hk"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9so8fmt3pS39"
      },
      "source": [
        "# **Frequency**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNEeeZv1o9x1"
      },
      "outputs": [],
      "source": [
        "# Calculating the Frequency of orders\n",
        "frequency_df = df.groupby('CustomerID')['InvoiceNo'].nunique().reset_index()\n",
        "frequency_df.columns = ['CustomerID', 'Frequency']\n",
        "print(\"Step 1: Frequency Calculation\")\n",
        "print(frequency_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZDlMhjDpdbd"
      },
      "outputs": [],
      "source": [
        "# Merging the Frequency values into the main DataFrame\n",
        "df = pd.merge(df, frequency_df, on='CustomerID', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnxMG8iWpuql"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RF-yAysvpu2H"
      },
      "outputs": [],
      "source": [
        "# Displaying the updated DataFrame\n",
        "print(\"\\nFrequency Calculation\")\n",
        "print(df[['CustomerID', 'Recency', 'Frequency']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFPanuksp8Fn"
      },
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6ssbiOEpZw_"
      },
      "source": [
        "***Monetary***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6gyZ89gpt8D"
      },
      "outputs": [],
      "source": [
        "# Calculating the Monetary Value\n",
        "df['Monetary'] = df['Quantity'] * df['UnitPrice']\n",
        "print(\"\\nStep 2: Monetary Calculation\")\n",
        "print(df[['CustomerID', 'Monetary']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_NkZMgTpWoT"
      },
      "outputs": [],
      "source": [
        "# Making new Column Monetary\n",
        "df['Monetary'] = df['Quantity'] * df['UnitPrice']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCsuIf2XqOtz"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBrDz8QpqT-L"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1H-i-ycuqXO4"
      },
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uG6Sm9FqZZa"
      },
      "outputs": [],
      "source": [
        "# Displaying the updated DataFrame\n",
        "print(\"\\nFrequency and Monetary Calculation\")\n",
        "print(df[['CustomerID', 'Recency', 'Frequency', 'Monetary']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dD2HlNmxqcju"
      },
      "outputs": [],
      "source": [
        "# Calculating unique values in 'Frequency' to check if there is any anamoly in our column\n",
        "unique_frequencies = df['Frequency'].unique()\n",
        "\n",
        "# Displaying the unique values\n",
        "print(\"Unique Values in Frequency:\")\n",
        "print(unique_frequencies)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AImuRxVZs2ua"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import skew\n",
        "#checking skewness because there is nothing else wrong in this column but it is giving us some wrong graphs\n",
        "# Calculating skewness of 'Frequency'\n",
        "frequency_skewness = skew(df['Frequency'])\n",
        "# Displaying the skewness value\n",
        "print(\"Skewness of Frequency:\", frequency_skewness)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nEKeVloquex"
      },
      "outputs": [],
      "source": [
        "#for the removel of skewness we will take logrithm of our column\n",
        "import numpy as np\n",
        "\n",
        "# Logarithmic transformation of 'Frequency'\n",
        "df['Frequency_Log'] = np.log1p(df['Frequency'])\n",
        "\n",
        "# Calculating skewness of the transformed 'Frequency'\n",
        "frequency_log_skewness = skew(df['Frequency_Log'])\n",
        "\n",
        "# Displaying the skewness value after transformation\n",
        "print(\"Skewness after Logarithmic Transformation:\", frequency_log_skewness)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0m7gFWK1uH2"
      },
      "source": [
        "Now as we have less than 1 skewness now we can proceed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uaKlyyrltBRb"
      },
      "outputs": [],
      "source": [
        "# Specify the number of bins (e.g., 4)\n",
        "num_bins = 4\n",
        "frequency_bins = pd.cut(df['Frequency_Log'], bins=num_bins, labels=['1', '2', '3', '4'])\n",
        "\n",
        "# Assigning the new bin labels to a column\n",
        "df['Frequency_Quartile'] = frequency_bins.astype(str)\n",
        "\n",
        "# Displaying the updated DataFrame with the transformed and binned 'Frequency'\n",
        "print(\"\\nUpdated DataFrame with Transformed and Binned Frequency\")\n",
        "print(df[['CustomerID', 'Recency', 'Frequency_Log', 'Monetary', 'Frequency_Quartile']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIMsivA9tTuY"
      },
      "outputs": [],
      "source": [
        "# Calculating unique values in 'Frequency_Quartile'\n",
        "unique_frequency_quartiles = df['Frequency_Quartile'].unique()\n",
        "\n",
        "# Displaying the unique values\n",
        "print(\"Unique Values in Frequency_Quartile:\")\n",
        "print(unique_frequency_quartiles)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdFyd0Y6ta72"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFZBmQ02tdhI"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfw8T9C-tgph"
      },
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THYNFB5Itpgn"
      },
      "outputs": [],
      "source": [
        "# Convert 'Frequency_Quartile' to integer type\n",
        "df['Frequency_Quartile'] = df['Frequency_Quartile'].astype(int)\n",
        "\n",
        "# Displaying the updated DataFrame with the transformed data types\n",
        "print(\"\\nUpdated DataFrame with Transformed Data Types\")\n",
        "print(df.dtypes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZW29T9rt43v"
      },
      "outputs": [],
      "source": [
        "# checking skewness of 'Recency'\n",
        "recency_skewness = skew(df['Recency'])\n",
        "\n",
        "# Displaying the skewness value\n",
        "print(\"Skewness of Recency:\", recency_skewness)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rId4Kvr9uVfw"
      },
      "outputs": [],
      "source": [
        "# Logarithmic transformation of 'Recency'\n",
        "df['Recency_Log'] = np.log1p(df['Recency'])\n",
        "\n",
        "# checking skewness after transformation\n",
        "recency_log_skewness = skew(df['Recency_Log'])\n",
        "print(\"Skewness of Recency after Logarithmic Transformation:\", recency_log_skewness)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Th0XBaImum6H"
      },
      "outputs": [],
      "source": [
        "# Calculating quartiles for the transformed 'Recency'\n",
        "recency_quartiles = pd.qcut(df['Recency_Log'], q=4, labels=['4', '3', '2', '1'])\n",
        "\n",
        "# Assigning quartiles to a new column\n",
        "df['Recency_Quartile'] = recency_quartiles.astype(str)\n",
        "\n",
        "# Displaying the updated DataFrame with the transformed and segmented 'Recency'\n",
        "print(\"\\nUpdated DataFrame with Transformed and Segmented Recency\")\n",
        "print(df[['CustomerID', 'Recency_Log', 'Recency_Quartile']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOElmliauqE_"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mv8xGOEvu1by"
      },
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eZ0mPJDu3x5"
      },
      "outputs": [],
      "source": [
        "# Convert 'Recency_Quartile' to integer type\n",
        "df['Recency_Quartile'] = df['Recency_Quartile'].astype(int)\n",
        "\n",
        "# Displaying the updated DataFrame with the transformed data types\n",
        "print(\"\\nUpdated DataFrame with Transformed Data Types\")\n",
        "print(df.dtypes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vlGa3i4vB9l"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMV7EIM12I-g"
      },
      "source": [
        "We have alread dealt with skewness we will remove the skewness fromthis column of Monetary too"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_Hvp2VLvE_O"
      },
      "outputs": [],
      "source": [
        "# checking skewness of 'Monetary'\n",
        "Monetary_skewness = skew(df['Monetary'])\n",
        "\n",
        "# Displaying the skewness value\n",
        "print(\"Skewness of Monetary:\", recency_skewness)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2EiFzqevU5y"
      },
      "outputs": [],
      "source": [
        "# adding a small constant to handle potential zero or negative values\n",
        "constant = 1\n",
        "df['Monetary_Log'] = np.log1p(df['Monetary'] + constant)\n",
        "\n",
        "# checking skewness after transformation\n",
        "monetary_log_skewness = skew(df['Monetary_Log'])\n",
        "print(\"Skewness of Monetary after Logarithmic Transformation:\", monetary_log_skewness)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZLlwMCdvawl"
      },
      "outputs": [],
      "source": [
        "# adding a constant to handle negative values\n",
        "constant_monetary = abs(df['Monetary'].min()) + 1\n",
        "df['Monetary_Log'] = np.log1p(df['Monetary'] + constant_monetary)\n",
        "\n",
        "# checking skewness after transformation\n",
        "monetary_log_skewness = skew(df['Monetary_Log'])\n",
        "print(\"Skewness of Monetary after Logarithmic Transformation:\", monetary_log_skewness)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7Hwmjcb2gRv"
      },
      "source": [
        "After cheking skwness we can see abnormality in our data and can guess somthing is wrong with it so will will count if thre anre some negative vakue in our data whic is not being removed with the addition of a constant value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4ROmcf7v4yh"
      },
      "outputs": [],
      "source": [
        "# Count of negative values in 'Monetary'\n",
        "negative_values_count = (df['Monetary'] < 0).sum()\n",
        "print(\"Count of Negative Values in Monetary:\", negative_values_count)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McXKk_Vuw0vO"
      },
      "outputs": [],
      "source": [
        "# Set negative values in 'Monetary' to zero\n",
        "df['Monetary'] = df['Monetary'].apply(lambda x: max(x, 0))\n",
        "\n",
        "# Logarithmic transformation of 'Monetary'\n",
        "df['Monetary_Log'] = np.log1p(df['Monetary'])\n",
        "\n",
        "# checking skewness after transformation\n",
        "monetary_log_skewness = skew(df['Monetary_Log'])\n",
        "print(\"Skewness of Monetary after Logarithmic Transformation:\", monetary_log_skewness)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmyvMe5I219J"
      },
      "source": [
        "No we have prepared our Monetary column too"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbQjJIzhxMTL"
      },
      "outputs": [],
      "source": [
        "# Calculating quartiles for the transformed 'Monetary'\n",
        "monetary_quartiles = pd.qcut(df['Monetary_Log'], q=4, labels=['1', '2', '3', '4'])\n",
        "\n",
        "# Assigning quartiles to a new column\n",
        "df['Monetary_Quartile'] = monetary_quartiles.astype(str)\n",
        "\n",
        "# Displaying the updated DataFrame with the transformed and segmented 'Monetary'\n",
        "print(\"\\nUpdated DataFrame with Transformed and Segmented Monetary\")\n",
        "print(df[['CustomerID', 'Monetary_Log', 'Monetary_Quartile']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-LzcGoixSCj"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDyVVo9ExTy2"
      },
      "outputs": [],
      "source": [
        "df.dtypes\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxNkFYEy3Djh"
      },
      "source": [
        "# Now Let's creat **RFM score**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sH_CXpxYxXQI"
      },
      "outputs": [],
      "source": [
        "# Assigning scores for Recency, Frequency, and Monetary\n",
        "df['Recency_Score'] = pd.to_numeric(df['Recency_Quartile'])\n",
        "df['Frequency_Score'] = pd.to_numeric(df['Frequency_Quartile'])\n",
        "df['Monetary_Score'] = pd.to_numeric(df['Monetary_Quartile'])\n",
        "\n",
        "# Combine scores to create RFM score\n",
        "df['RFM_Score'] = df['Recency_Score'].astype(str) + df['Frequency_Score'].astype(str) + df['Monetary_Score'].astype(str)\n",
        "\n",
        "# Displaying the updated DataFrame with RFM scores\n",
        "print(\"\\nUpdated DataFrame with RFM Scores\")\n",
        "print(df[['CustomerID', 'Recency_Score', 'Frequency_Score', 'Monetary_Score', 'RFM_Score']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AYvBSSGx_ig"
      },
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BHj7d0IyCiE"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MRc7WWuyF4R"
      },
      "outputs": [],
      "source": [
        "# Convert RFM_Score to numeric\n",
        "df['RFM_Score'] = pd.to_numeric(df['RFM_Score'])\n",
        "\n",
        "# Displaying the updated DataFrame with numeric RFM scores\n",
        "print(\"\\nUpdated DataFrame with Numeric RFM Scores\")\n",
        "print(df[['CustomerID', 'Recency_Score', 'Frequency_Score', 'Monetary_Score', 'RFM_Score']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwHTEPcF3Ih1"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxwMmBDV3UMm"
      },
      "source": [
        "Now we will segment our customer according to there RFM values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2hCKyHf3d5v"
      },
      "outputs": [],
      "source": [
        "# Adjusting segmentation based on sample RFM scores\n",
        "segment_dict = {\n",
        "    'High-Value Customers': ['444'],\n",
        "    'Potential Loyal Customers': ['344', '434'],\n",
        "    'Big Spenders': ['424', '423', '414', '412', '411', '414', '434'],\n",
        "    'Recent Customers': ['244', '234', '224', '213', '214'],\n",
        "    'Churn Risk Customers': ['111', '113', '121', '122', '131', '132']\n",
        "}\n",
        "\n",
        "# Applying segmentation to create a new 'Segment' column\n",
        "def assign_segment(rfm_score):\n",
        "    for segment, score_list in segment_dict.items():\n",
        "        if rfm_score in score_list:\n",
        "            return segment\n",
        "    return 'Other'  # Default segment if not found in any defined segments\n",
        "\n",
        "# Applying segmentation to create a new 'Segment' column\n",
        "df['Segment'] = df['RFM_Score'].astype(str).apply(assign_segment)\n",
        "\n",
        "# Displaying the updated DataFrame with the 'Segment' column\n",
        "print(\"\\nUpdated DataFrame with Segmentation\")\n",
        "print(df[['CustomerID', 'RFM_Score', 'Segment']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XaXJtv0a3u1I"
      },
      "outputs": [],
      "source": [
        "# To checking if all the records are correctly assignted to correct segment let's Displaying two samples from each segment with index\n",
        "for segment in segment_dict.keys():\n",
        "    segment_samples = df[df['Segment'] == segment].sample(2).reset_index()\n",
        "    print(f\"\\nSamples from {segment} segment:\")\n",
        "    print(segment_samples[['index', 'CustomerID', 'RFM_Score', 'Segment']])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-K6WyteT7dYh"
      },
      "outputs": [],
      "source": [
        "# Adjusting segmentation based on RFM scores\n",
        "segment_dict = {\n",
        "    'High-Value Customers': ['444'],\n",
        "    'Potential Loyal Customers': ['344', '434','433','334','332','333'],\n",
        "    'Big Spenders': ['424', '423', '414', '412', '411', '434', '442', '441', '443','432','114','324'],\n",
        "    'Recent Customers': ['244', '234', '224', '213', '214', '431','134', '112', '223','313', '314', '322', '323', '311', '312', '222', '422', '421', '212', '211', '413', '124', '123', '221', '321', '331',  '233', '231', '232'],\n",
        "    'Churn Risk Customers': ['111', '113', '121', '122', '131', '132','133']\n",
        "}\n",
        "\n",
        "# Function to Assigning segment based on RFM Score\n",
        "def assign_segment(rfm_score):\n",
        "    for segment, scores in segment_dict.items():\n",
        "        if rfm_score in scores:\n",
        "            return segment\n",
        "    return 'Other'  # Default for any other case\n",
        "\n",
        "# Applying segmentation to create a new 'Segment' column\n",
        "df['Segment'] = df['RFM_Score'].astype(str).apply(assign_segment)\n",
        "\n",
        "# Displaying the updated DataFrame with the 'Segment' column\n",
        "print(\"\\nUpdated DataFrame with Segmentation\")\n",
        "print(df[['CustomerID', 'RFM_Score', 'Segment']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LanLL2hp5WSp"
      },
      "outputs": [],
      "source": [
        "# Displaying total count of each segment\n",
        "segment_counts = df['Segment'].value_counts().reset_index()\n",
        "segment_counts.columns = ['Segment', 'Count']\n",
        "print(\"\\nTotal Count of Each Segment:\")\n",
        "print(segment_counts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6yLttZp0VpC"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNRYMkl1AdEO"
      },
      "outputs": [],
      "source": [
        "# Creating a bar plot for the distribution of customers across segments\n",
        "plt.figure(figsize=(15, 6))\n",
        "sns.countplot(x='Segment', data=df, palette='viridis')\n",
        "\n",
        "# Set plot labels and title\n",
        "plt.xlabel('Customer Segment')\n",
        "plt.ylabel('Number of Customers')\n",
        "plt.title('Distribution of Customers Across Segments')\n",
        "\n",
        "# showing the total count on each bar\n",
        "for index, value in enumerate(df['Segment'].value_counts()):\n",
        "    plt.text(index, value + 5, str(value), ha='center', va='bottom')\n",
        "\n",
        "# showing the plot\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ns9XtSn2s2h"
      },
      "source": [
        "analyze key metrics such as average Recency, Frequency, and Monetary values within each segment. let's Calculating and compare the means for each metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdvZMBBW2JRS"
      },
      "outputs": [],
      "source": [
        "# Group by 'Simplified_Segment_Name' and Calculating the mean for each metric\n",
        "segment_metrics = df.groupby('Segment').agg({\n",
        "    'Recency': 'mean',\n",
        "    'Frequency': 'mean',\n",
        "    'Monetary': 'mean'\n",
        "}).reset_index()\n",
        "\n",
        "# Displaying the Calculatingd means\n",
        "print(\"\\nAverage Metrics Within Each Segment:\")\n",
        "print(segment_metrics)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMOlD6ijEUZw"
      },
      "outputs": [],
      "source": [
        "#there is i think out liers in churn risk why there is 230% is being shown there to chek that we need to chek for any outliers\n",
        "# Filter data for Churn Risk Customers segment\n",
        "churn_risk_data = df[df['Segment'] == 'Churn Risk Customers']\n",
        "\n",
        "# Set the style for the plot\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Creating a box plot for Recency in Churn Risk Customers segment\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x=churn_risk_data['Recency'], palette='viridis')\n",
        "\n",
        "# Set plot labels and title\n",
        "plt.xlabel('Recency in Churn Risk Customers')\n",
        "plt.title('Distribution of Recency in Churn Risk Customers Segment')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJNfLJmH3IMU"
      },
      "source": [
        "visualize these average metrics within each segment to gain a clearer understanding.Let's create bar plots for each metric to compare the values across segments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJM_vVsDB2zF"
      },
      "outputs": [],
      "source": [
        "# Calculating average recency for each segment\n",
        "avg_recency = df.groupby('Segment')['Recency'].mean().reset_index()\n",
        "\n",
        "# Set the style for the plot\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Creatinga bar plot for average Recency across segments\n",
        "plt.figure(figsize=(15, 6))\n",
        "ax = sns.barplot(x='Segment', y='Recency', data=avg_recency, palette='viridis')\n",
        "\n",
        "# Annotate the bars with their respective average recency values\n",
        "for p in ax.patches:\n",
        "    ax.annotate(f'{p.get_height():.2f}%', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                ha='center', va='center', xytext=(0, 10), textcoords='offset points', fontsize=10, color='black')\n",
        "\n",
        "# Set plot labels and title\n",
        "plt.xlabel('Customer Segment')\n",
        "plt.ylabel('Average Recency')\n",
        "plt.title('Average Recency Across Customer Segments')\n",
        "\n",
        "# showing the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNkpEayTCVNM"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define custom colors for each segment\n",
        "segment_colors = {\n",
        "    'High-Value Customers': 'skyblue',\n",
        "    'Potential Loyal Customers': 'lightcoral',\n",
        "    'Big Spenders': 'lightgreen',\n",
        "    'Recent Customers': 'lightsalmon',\n",
        "    'Churn Risk Customers': 'lightblue'\n",
        "}\n",
        "\n",
        "# Creating a pie chart for Recency across segments\n",
        "plt.figure(figsize=(15, 15))\n",
        "\n",
        "# Data for Recency\n",
        "recency_data = df.groupby('Segment')['Recency'].mean()\n",
        "labels = recency_data.index\n",
        "sizes = recency_data.values\n",
        "\n",
        "# Creating a pie chart with custom colors\n",
        "plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90, colors=[segment_colors[segment] for segment in labels])\n",
        "\n",
        "# Draw a circle at the center of the pie to make it look like a donut\n",
        "centre_circle = plt.Circle((0, 0), 0.70, fc='white')\n",
        "fig = plt.gcf()\n",
        "fig.gca().add_artist(centre_circle)\n",
        "\n",
        "# Set plot title\n",
        "plt.title('Average Recency Across Customer Segments')\n",
        "\n",
        "# showing the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02tUuL5S3rWy"
      },
      "source": [
        "Average Frequency graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBHf2Vu93RWB"
      },
      "outputs": [],
      "source": [
        "# Set the style for the plot\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Bar plot for Average Frequency\n",
        "plt.figure(figsize=(15, 6))\n",
        "sns.barplot(x='Segment', y='Frequency', data=segment_metrics, palette='viridis')\n",
        "plt.title('Average Frequency Within Each Segment')\n",
        "plt.xlabel('Customer Segment')\n",
        "plt.ylabel('Average Frequency')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvIVsrt-3xP6"
      },
      "source": [
        "Average Monetary Value Within Each Segment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjBk3vtr3vxp"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Set the style for the plot\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Bar plot for Average Monetary Value\n",
        "plt.figure(figsize=(15, 6))\n",
        "sns.barplot(x='Segment', y='Monetary', data=segment_metrics, palette='viridis')\n",
        "plt.title('Average Monetary Value Within Each Segment')\n",
        "plt.xlabel('Simplified Customer Segment')\n",
        "plt.ylabel('Average Monetary Value')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aexURVZK478b"
      },
      "source": [
        "High-Value customers may not be frequent shoppers but have moderate spending.\n",
        "Potential Loyal customers show recent activity, higher frequency, and moderate spending.\n",
        "Big Spenders are very recent and have both high frequency and high spending.\n",
        "\n",
        "**Targeted marketing strategies**:\n",
        "\n",
        "High-Value customers might be incentivized to increase their frequency, while efforts for Potential Loyal customers Should focus on retaining their loyalty. Big Spenders could be targeted with exclusive offers to maintain their high spending levels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A3Hquwo6EPQ"
      },
      "source": [
        "# **Demographics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1Lj0i2E33HE"
      },
      "outputs": [],
      "source": [
        "# Group data by Country and Simplified_Segment_Name, and Calculating customer counts\n",
        "segment_distribution = df.groupby(['Country', 'Segment']).size().reset_index(name='CustomerCount')\n",
        "\n",
        "# Displaying the first few rows of the resulting DataFrame\n",
        "print(segment_distribution.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZeQMavD76J7O"
      },
      "outputs": [],
      "source": [
        "# Set the style for the plots\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Creatinga bar plot to visualize the distribution of customer segments by country\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(x='Country', y='CustomerCount', hue='Segment', data=segment_distribution)\n",
        "plt.title('Distribution of Customer Segments by Country')\n",
        "plt.xlabel('Country')\n",
        "plt.ylabel('Customer Count')\n",
        "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
        "plt.legend(title='Customer Segment')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PA0lIV76Pfe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Set the style for the plots\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Creating a bar plot with a logarithmic scale for the y-axis\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(x='Country', y='CustomerCount', hue='Segment', data=segment_distribution)\n",
        "plt.title('Distribution of Customer Segments by Country')\n",
        "plt.xlabel('Country')\n",
        "plt.ylabel('Customer Count (log scale)')\n",
        "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
        "plt.yscale('log')  # Set y-axis to logarithmic scale\n",
        "plt.legend(title='Customer Segment')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBVcIUe87DXV"
      },
      "source": [
        "Using heat map for better understanding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKjii_VI6vnz"
      },
      "outputs": [],
      "source": [
        "# Pivot the data to create a matrix for the heatmap\n",
        "heatmap_data = segment_distribution.pivot(index='Country', columns='Segment', values='CustomerCount')\n",
        "\n",
        "# Set the style for the plot\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Creatinga heatmap\n",
        "plt.figure(figsize=(14, 10))\n",
        "sns.heatmap(heatmap_data, annot=True, fmt=\".2f\", cmap=\"YlGnBu\", linewidths=.5)\n",
        "plt.title('Distribution of Customer Segments by Country (Heatmap)')\n",
        "plt.xlabel('Customer Segment')\n",
        "plt.ylabel('Country')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4A9e8KAL7HEg"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# Creating a choropleth map\n",
        "fig = px.choropleth(\n",
        "    segment_distribution,\n",
        "    locations='Country',\n",
        "    locationmode='country names',\n",
        "    color='Segment',\n",
        "    title='Customer Segment Distribution by Country',\n",
        "    color_discrete_map={'High-Value': 'blue', 'Potential Loyal': 'green', 'Big Spenders': 'red'},\n",
        "    labels={'Segment': 'Customer Segment'}\n",
        ")\n",
        "\n",
        "# showing the map\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7wgCpS27z1p"
      },
      "outputs": [],
      "source": [
        "# Group data by Country and Simplified_Segment_Name, and Calculating customer counts\n",
        "segment_distribution = df.groupby(['Country', 'Segment']).size().reset_index(name='CustomerCount')\n",
        "\n",
        "# Displaying the resulting DataFrame\n",
        "print(segment_distribution)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-zd9gnlCFq0"
      },
      "outputs": [],
      "source": [
        "# Set the option to Displaying all rows and columns\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "# Displaying the resulting DataFrame\n",
        "print(segment_distribution)\n",
        "\n",
        "# Reset the options to the default values if needed\n",
        "pd.reset_option('display.max_rows')\n",
        "pd.reset_option('display.max_columns')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlhwWM_4FtYQ"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlBXb3EROL9M"
      },
      "source": [
        "# **Suggestions:**\n",
        "1. **United Kingdom Insights:**\n",
        "   - Given the substantial customer count in the \"High-Value\" segment in the United Kingdom, consider implementing personalized promotions or loyalty programs to further engage and retain this large customer base locally.\n",
        "\n",
        "2. **Potential Loyal Customers:**\n",
        "   - Identify common characteristics or behaviors among customers in the \"Potential Loyal\" segment across various countries.\n",
        "   - Target these customers with promotions, such as exclusive discounts, to encourage repeat purchases and foster loyalty.\n",
        "\n",
        "3. **Big Spenders Worldwide:**\n",
        "   - Recognize the global presence of the \"Big Spenders\" segment and tailor international marketing strategies to attract and retain high-value customers globally.\n",
        "\n",
        "4. **Understanding Recent Customers:**\n",
        "   - Investigate factors influencing the lower customer count in the \"Recent Customers\" segment across countries, such as seasonality or external events.\n",
        "   - Implement marketing or outreach campaigns to re-engage recent customers and encourage additional purchases.\n",
        "\n",
        "5. **Diversification in Other Countries:**\n",
        "   - Explore business expansion opportunities in countries where certain segments are underrepresented.\n",
        "   - Conduct market research to understand the preferences and behaviors of customers in these countries and tailor marketing strategies accordingly.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4q7PWtWMuIK"
      },
      "outputs": [],
      "source": [
        "# Group by InvoiceNo and aggregate products\n",
        "invoice_products = df.groupby('CustomerID')['Description'].unique().reset_index()\n",
        "\n",
        "# Displaying the resulting DataFrame\n",
        "print(invoice_products)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ec_yUqyZbPjY"
      },
      "outputs": [],
      "source": [
        "df.columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUJ-s6oWgKuq"
      },
      "outputs": [],
      "source": [
        "# Group by InvoiceNo and aggregate the Description into lists\n",
        "df['Purchased_Products'] = df.groupby('InvoiceNo')['Description'].agg(list)\n",
        "\n",
        "# Displaying the first few rows of the DataFrame with the new 'Purchased_Products' column\n",
        "print(df[['InvoiceNo', 'Purchased_Products']].tail())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PXyREIugdqA"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fduyxXlBYyP"
      },
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpmmkQWnRkPQ"
      },
      "outputs": [],
      "source": [
        "# Print the actual values in the 'Purchased_Products' column for each segment, handling NaN values\n",
        "for segment_name, segment_data in df.groupby('Segment'):\n",
        "    print(f\"\\n--- Purchased Products for {segment_name} ---\")\n",
        "    print(segment_data['Purchased_Products'].dropna())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUmuRdRnji46"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set the style for the plot\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Analyze the most popular products within each customer segment\n",
        "for segment_name, segment_data in df.groupby('Segment'):\n",
        "    # Drop NaN values from the 'Purchased_Products' column\n",
        "    products = segment_data['Purchased_Products'].dropna()\n",
        "\n",
        "    if not products.empty:\n",
        "        # Concatenate the lists of purchased products for each customer in the segment\n",
        "        all_products = [product for products in products for product in products]\n",
        "        # Count the occurrences of each product\n",
        "        product_counts = pd.Series(all_products).value_counts().head(5)  # Displaying the top 5 products\n",
        "\n",
        "        # Creatinga horizontal bar plot\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        sns.barplot(x=product_counts, y=product_counts.index, palette='viridis')\n",
        "        # Set plot labels and title\n",
        "        plt.xlabel('Number of Purchases')\n",
        "        plt.ylabel('Product')\n",
        "        plt.title(f'Top 5 Products for {segment_name}')\n",
        "        # Show the plot\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(f\"No purchased products for {segment_name}.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBCsfMdNTo8A"
      },
      "source": [
        "# **Result:**\n",
        "\n",
        "- **High-Value Customers:** They seem to frequently purchase items like \"DOTCOM POSTAGE,\" \"JUMBO BAG RED RETROSPOT,\" and \"WHITE HANGING HEART T-LIGHT HOLDER.\"\n",
        "\n",
        "- **Potential Loyal Customers:** Popular products include \"WHITE HANGING HEART T-LIGHT HOLDER,\" \"REGENCY CAKESTAND 3 TIER,\" and \"LUNCH BAG RED RETROSPOT.\"\n",
        "\n",
        "- **Big Spenders:** The top products for this segment include \"PACK OF 72 RETROSPOT CAKE CASES,\" \"JUMBO BAG RED RETROSPOT,\" and \"REGENCY CAKESTAND 3 TIER.\"\n",
        "\n",
        "- **Recent Customers:** There are no specific popular products identified for this segment based on the current data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIWo63g1acdP"
      },
      "source": [
        "**Are there specific products or categories that the \"Big Spenders\" segment tends to purchase more frequently?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBVCsRgeabbv"
      },
      "outputs": [],
      "source": [
        "# Filter the DataFrame for the \"Big Spenders\" segment\n",
        "big_spenders_df = df[df['Segment'] == 'Big Spenders']\n",
        "\n",
        "# Explore the most frequently purchased products\n",
        "top_products = big_spenders_df.groupby('Description')['Quantity'].sum().sort_values(ascending=False).head(10)\n",
        "\n",
        "# Explore the most frequently purchased categories (we have 'StockCode' represents categories)\n",
        "top_categories = big_spenders_df.groupby('StockCode')['Quantity'].sum().sort_values(ascending=False).head(10)\n",
        "\n",
        "# Displaying the top products and categories\n",
        "print(\"\\nTop Products Purchased by Big Spenders:\")\n",
        "print(top_products)\n",
        "\n",
        "print(\"\\nTop Categories Purchased by Big Spenders:\")\n",
        "print(top_categories)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmklQGTraogp"
      },
      "outputs": [],
      "source": [
        "# Set up the plotting environment\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Plotting the top products\n",
        "plt.subplot(1, 2, 1)\n",
        "top_products.plot(kind='bar', color='skyblue')\n",
        "plt.title('Top Products Purchased by Big Spenders')\n",
        "plt.xlabel('Product Description')\n",
        "plt.ylabel('Total Quantity Purchased')\n",
        "\n",
        "# Plotting the top categories\n",
        "plt.subplot(1, 2, 2)\n",
        "top_categories.plot(kind='bar', color='lightcoral')\n",
        "plt.title('Top Categories Purchased by Big Spenders')\n",
        "plt.xlabel('Stock Code')\n",
        "plt.ylabel('Total Quantity Purchased')\n",
        "\n",
        "# Adjusting layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# showing the plots\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNl5nKlcwobG"
      },
      "outputs": [],
      "source": [
        "# Set up the plotting environment\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "\n",
        "top_products.plot(kind='bar', color='skyblue')\n",
        "plt.title('Top Products Purchased by Big Spenders')\n",
        "plt.xlabel('Product Description')\n",
        "plt.ylabel('Total Quantity Purchased')\n",
        "\n",
        "\n",
        "\n",
        "# showing the plots\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIopFlsOrkCe"
      },
      "source": [
        "**specific products or categories that the \"Big Spenders\" segment tends to purchase more frequently?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egxXoGLKrcfG"
      },
      "outputs": [],
      "source": [
        "# Filter data for Potential Loyal Customers\n",
        "potential_loyal_data = df[df['Segment'] == 'Potential Loyal Customers']\n",
        "\n",
        "# Calculating the quantity of each product\n",
        "potential_loyal_products = potential_loyal_data.groupby('Description')['Quantity'].sum().sort_values(ascending=False)\n",
        "\n",
        "# Displaying the top products\n",
        "print(\"Top Products Purchased by Potential Loyal Customers:\")\n",
        "print(potential_loyal_products.head(10))\n",
        "\n",
        "# Calculating the quantity of each category (StockCode)\n",
        "potential_loyal_categories = potential_loyal_data.groupby('StockCode')['Quantity'].sum().sort_values(ascending=False)\n",
        "\n",
        "# Displaying the top categories\n",
        "print(\"\\nTop Categories Purchased by Potential Loyal Customers:\")\n",
        "print(potential_loyal_categories.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6_mjq2Jr8xQ"
      },
      "outputs": [],
      "source": [
        "# Set up subplots\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Plotting the top products\n",
        "plt.subplot(1, 2, 1)\n",
        "potential_loyal_products.head(10).plot(kind='bar', color='skyblue')\n",
        "plt.title('Top Products Purchased by Potential Loyal Customers')\n",
        "plt.xlabel('Product Description')\n",
        "plt.ylabel('Quantity')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "# Plotting the top categories\n",
        "plt.subplot(1, 2, 2)\n",
        "potential_loyal_categories.head(10).plot(kind='bar', color='lightcoral')\n",
        "plt.title('Top Categories Purchased by Potential Loyal Customers')\n",
        "plt.xlabel('StockCode')\n",
        "plt.ylabel('Quantity')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "# Adjusting the layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# showing the plots\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpSsRDOarvWg"
      },
      "source": [
        "specific products or categories that the \"High-Value Customers\" segment tends to purchase more frequently?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJercuttrxML"
      },
      "outputs": [],
      "source": [
        "# Filter data for High-Value Customers\n",
        "high_value_data = df[df['Segment'] == 'High-Value Customers']\n",
        "\n",
        "# Calculating the quantity of each product\n",
        "high_value_products = high_value_data.groupby('Description')['Quantity'].sum().sort_values(ascending=False)\n",
        "\n",
        "# Displaying the top products\n",
        "print(\"\\nTop Products Purchased by High-Value Customers:\")\n",
        "print(high_value_products.head(10))\n",
        "\n",
        "# Calculating the quantity of each category (StockCode)\n",
        "high_value_categories = high_value_data.groupby('StockCode')['Quantity'].sum().sort_values(ascending=False)\n",
        "\n",
        "# Displaying the top categories\n",
        "print(\"\\nTop Categories Purchased by High-Value Customers:\")\n",
        "print(high_value_categories.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmXWD_GQsKoH"
      },
      "outputs": [],
      "source": [
        "# Set up subplots\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Plotting the top products\n",
        "plt.subplot(1, 2, 1)\n",
        "high_value_products.head(10).plot(kind='bar', color='skyblue')\n",
        "plt.title('Top Products Purchased by High-Value Customers')\n",
        "plt.xlabel('Product Description')\n",
        "plt.ylabel('Quantity')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "# Plotting the top categories\n",
        "plt.subplot(1, 2, 2)\n",
        "high_value_categories.head(10).plot(kind='bar', color='lightcoral')\n",
        "plt.title('Top Categories Purchased by High-Value Customers')\n",
        "plt.xlabel('StockCode')\n",
        "plt.ylabel('Quantity')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "# Adjusting the layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# showing the plots\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQzHSxxmav5D"
      },
      "source": [
        "**Loyalty and Retention:**\n",
        "**What is the average time gap between purchases for the \"Big Spenders\" segment?**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nf5nmyXeawES"
      },
      "outputs": [],
      "source": [
        "# we have df is we have DataFrame with the relevant columns\n",
        "big_spenders_data = df[df['Segment'] == 'Big Spenders']\n",
        "\n",
        "# Sort the data by CustomerID and InvoiceDate\n",
        "big_spenders_data = big_spenders_data.sort_values(by=['CustomerID', 'InvoiceDate'])\n",
        "\n",
        "# Calculating the time gap between consecutive purchases for each customer\n",
        "big_spenders_data['Time_Gap'] = big_spenders_data.groupby('CustomerID')['InvoiceDate'].diff()\n",
        "\n",
        "# Calculating the average time gap for the \"Big Spenders\" segment\n",
        "average_time_gap = big_spenders_data['Time_Gap'].mean()\n",
        "\n",
        "# Displaying the result\n",
        "print(\"Average Time Gap between Purchases for Big Spenders:\", average_time_gap)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-QF_RR5jhEA"
      },
      "outputs": [],
      "source": [
        "# Set the threshold for the extended period (e.g., 3 months)\n",
        "extended_period_threshold = 3\n",
        "\n",
        "# Identify high-value customers\n",
        "high_value_customers = df[df['Segment'] == 'High-Value Customers']['CustomerID'].unique()\n",
        "\n",
        "# Filter data for high-value customers\n",
        "high_value_data = df[df['CustomerID'].isin(high_value_customers)]\n",
        "\n",
        "# Calculating the purchase frequency for each high-value customer within the extended period\n",
        "consistent_purchase_counts = high_value_data.groupby('CustomerID')['InvoiceDate'].diff().dt.days.le(extended_period_threshold).sum()\n",
        "\n",
        "# Displaying the result\n",
        "print(\"Number of High-Value Customers with Consistent Purchases:\", consistent_purchase_counts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlHP_yMJjhbf"
      },
      "outputs": [],
      "source": [
        "# Set the threshold for the extended period (e.g., 1 months)\n",
        "extended_period_threshold = 1\n",
        "\n",
        "# Creating a DataFrame to store the results\n",
        "consistent_purchase_results = pd.DataFrame(columns=['CustomerID', 'Segment', 'ConsistentPurchaseCount'])\n",
        "\n",
        "# Iterate over each segment\n",
        "for segment in segment_dict.keys():\n",
        "    # Identify customers in the current segment\n",
        "    segment_customers = df[df['Segment'] == segment]['CustomerID'].unique()\n",
        "\n",
        "    # Filter data for the current segment\n",
        "    segment_data = df[df['CustomerID'].isin(segment_customers)]\n",
        "\n",
        "    # Calculating the purchase frequency for each customer within the extended period\n",
        "    consistent_purchase_count = segment_data.groupby('CustomerID')['InvoiceDate'].diff().dt.days.le(extended_period_threshold).sum()\n",
        "\n",
        "    # Append the result to the DataFrame\n",
        "    consistent_purchase_results = consistent_purchase_results.append({'CustomerID': segment_customers[0], 'Segment': segment, 'ConsistentPurchaseCount': consistent_purchase_count}, ignore_index=True)\n",
        "\n",
        "# Displaying the results\n",
        "print(\"Consistent Purchase Count for Each Segment:\")\n",
        "print(consistent_purchase_results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KU-4M85Gw9vT"
      },
      "source": [
        "**Recomendations on Frequency**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVFKC66mxFuy"
      },
      "source": [
        "**Churn Risk Customers:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqBqzV4VobPI"
      },
      "outputs": [],
      "source": [
        "# Calculating average frequency for Churn Risk Customers\n",
        "churn_avg_frequency = df[df['Segment'] == 'Churn Risk Customers']['Frequency'].mean()\n",
        "print(\"Average Frequency for Churn Risk Customers:\", churn_avg_frequency)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Dvcqrj5xN16"
      },
      "source": [
        "**Recent Customers:**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4bKLe5CxJJJ"
      },
      "outputs": [],
      "source": [
        "# Calculating average frequency for Recent Customers\n",
        "recent_avg_frequency = df[df['Segment'] == 'Recent Customers']['Frequency'].mean()\n",
        "print(\"Average Frequency for Recent Customers:\", recent_avg_frequency)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mC74_9m4xWbr"
      },
      "source": [
        "**Potential Loyal Customers:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-EWDkgTxTbm"
      },
      "outputs": [],
      "source": [
        "# Calculating average frequency for Potential Loyal Customers\n",
        "loyal_avg_frequency = df[df['Segment'] == 'Potential Loyal Customers']['Frequency'].mean()\n",
        "print(\"Average Frequency for Potential Loyal Customers:\", loyal_avg_frequency)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-PC0ZZ4yGV7"
      },
      "outputs": [],
      "source": [
        "# Calculating average frequency for each segment\n",
        "churn_avg_frequency = df[df['Segment'] == 'Churn Risk Customers']['Frequency'].mean()\n",
        "recent_avg_frequency = df[df['Segment'] == 'Recent Customers']['Frequency'].mean()\n",
        "loyal_avg_frequency = df[df['Segment'] == 'Potential Loyal Customers']['Frequency'].mean()\n",
        "\n",
        "# Plotting the average frequencies with annotations\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar(['Churn Risk', 'Recent Customers', 'Potential Loyal'], [churn_avg_frequency, recent_avg_frequency, loyal_avg_frequency], color=['lightcoral', 'skyblue', 'gold'])\n",
        "\n",
        "# addinging annotations on each bar\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "plt.title('Average Frequency for Different Customer Segments')\n",
        "plt.xlabel('Customer Segments')\n",
        "plt.ylabel('Average Frequency')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nfiq5PBwyRoJ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculating average frequency for each segment\n",
        "churn_avg_frequency = df[df['Segment'] == 'Churn Risk Customers']['Frequency'].mean()\n",
        "recent_avg_frequency = df[df['Segment'] == 'Recent Customers']['Frequency'].mean()\n",
        "loyal_avg_frequency = df[df['Segment'] == 'Potential Loyal Customers']['Frequency'].mean()\n",
        "high_value_avg_frequency = df[df['Segment'] == 'High-Value Customers']['Frequency'].mean()\n",
        "big_spenders_avg_frequency = df[df['Segment'] == 'Big Spenders']['Frequency'].mean()\n",
        "\n",
        "# Plotting the average frequencies with annotations\n",
        "plt.figure(figsize=(12, 8))\n",
        "bars = plt.bar(['Churn Risk', 'Recent Customers', 'Potential Loyal', 'High-Value Customers', 'Big Spenders'],\n",
        "               [churn_avg_frequency, recent_avg_frequency, loyal_avg_frequency, high_value_avg_frequency, big_spenders_avg_frequency],\n",
        "               color=['lightcoral', 'skyblue', 'gold', 'mediumseagreen', 'orchid'])\n",
        "\n",
        "# Adding annotations on each bar\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "plt.title('Average Frequency for Different Customer Segments')\n",
        "plt.xlabel('Customer Segments')\n",
        "plt.ylabel('Average Frequency')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6HBUB7h00Up"
      },
      "source": [
        "**Location wise Frequency**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSOeyZSizqbl"
      },
      "outputs": [],
      "source": [
        "# Group data by Country and Calculating average frequency\n",
        "country_frequency = df.groupby('Country')['Frequency'].mean().reset_index()\n",
        "\n",
        "# Sort by average frequency in descending order\n",
        "sorted_countries = country_frequency.sort_values(by='Frequency', ascending=False)\n",
        "\n",
        "# Extract top 5 and least 5 countries\n",
        "top_5_countries = sorted_countries.head(5)\n",
        "least_5_countries = sorted_countries.tail(5)\n",
        "\n",
        "# Displaying the results\n",
        "print(\"Top 5 Countries (Highest Average Frequency):\")\n",
        "print(top_5_countries)\n",
        "\n",
        "print(\"\\nLeast 5 Countries (Lowest Average Frequency):\")\n",
        "print(least_5_countries)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z43zdEEp1Nuo"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set up the plotting environment\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Plot the top 5 countries with data values\n",
        "plt.subplot(1, 2, 1)\n",
        "bars = plt.bar(top_5_countries['Country'], top_5_countries['Frequency'], color='skyblue')\n",
        "plt.title('Top 5 Countries (Highest Average Frequency)')\n",
        "plt.xlabel('Country')\n",
        "plt.ylabel('Average Frequency')\n",
        "\n",
        "# Displaying data values on top of the bars\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom')\n",
        "\n",
        "# Plot the least 5 countries with data values\n",
        "plt.subplot(1, 2, 2)\n",
        "bars = plt.bar(least_5_countries['Country'], least_5_countries['Frequency'], color='lightcoral')\n",
        "plt.title('Least 5 Countries (Lowest Average Frequency)')\n",
        "plt.xlabel('Country')\n",
        "plt.ylabel('Average Frequency')\n",
        "\n",
        "# Displaying data values on top of the bars\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom')\n",
        "\n",
        "# Adjusting the layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plots\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDJ1dh1937LV"
      },
      "source": [
        "**Monetary:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nnMPCVO1Yc-"
      },
      "outputs": [],
      "source": [
        "# Calculating average monetary value for each segment\n",
        "average_monetary = df.groupby('Segment')['Monetary'].mean().reset_index()\n",
        "\n",
        "# Set up the plotting environment\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Plotting Average Monetary Value for Each Segment\n",
        "bar_plot = sns.barplot(x='Segment', y='Monetary', data=average_monetary, palette='viridis')\n",
        "plt.title('Average Monetary Value for Each Segment')\n",
        "plt.xlabel('Segment')\n",
        "plt.ylabel('Average Monetary Value')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "# Annotate with numbers on top of the bars\n",
        "for index, value in enumerate(average_monetary['Monetary']):\n",
        "    bar_plot.text(index, value, round(value, 2), ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "# showing the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7fCkoix6SRz"
      },
      "source": [
        "**Segments country wise**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4OsS2Gv6XOg"
      },
      "outputs": [],
      "source": [
        "# Find the country with the most customers in each segment\n",
        "recent_customers_country = df[df['Segment'] == 'Recent Customers']['Country'].value_counts().idxmax()\n",
        "big_spenders_country = df[df['Segment'] == 'Big Spenders']['Country'].value_counts().idxmax()\n",
        "churn_risk_country = df[df['Segment'] == 'Churn Risk Customers']['Country'].value_counts().idxmax()\n",
        "potential_loyal_country = df[df['Segment'] == 'Potential Loyal Customers']['Country'].value_counts().idxmax()\n",
        "high_value_country = df[df['Segment'] == 'High-Value Customers']['Country'].value_counts().idxmax()\n",
        "\n",
        "recent_customers_count = df[df['Segment'] == 'Recent Customers']['Country'].value_counts().max()\n",
        "big_spenders_count = df[df['Segment'] == 'Big Spenders']['Country'].value_counts().max()\n",
        "churn_risk_count = df[df['Segment'] == 'Churn Risk Customers']['Country'].value_counts().max()\n",
        "potential_loyal_count = df[df['Segment'] == 'Potential Loyal Customers']['Country'].value_counts().max()\n",
        "high_value_count = df[df['Segment'] == 'High-Value Customers']['Country'].value_counts().max()\n",
        "\n",
        "print(f\"Recent Customers: Country - {recent_customers_country}, Count - {recent_customers_count}\")\n",
        "print(f\"Big Spenders: Country - {big_spenders_country}, Count - {big_spenders_count}\")\n",
        "print(f\"Churn Risk Customers: Country - {churn_risk_country}, Count - {churn_risk_count}\")\n",
        "print(f\"Potential Loyal Customers: Country - {potential_loyal_country}, Count - {potential_loyal_count}\")\n",
        "print(f\"High-Value Customers: Country - {high_value_country}, Count - {high_value_count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejfVWgmV8fWg"
      },
      "outputs": [],
      "source": [
        "# Set up the plotting environment\n",
        "plt.figure(figsize=(15, 8))\n",
        "\n",
        "# Plotting Recent Customers\n",
        "plt.subplot(2, 3, 1)\n",
        "sns.countplot(x='Country', data=df[df['Segment'] == 'Recent Customers'], order=df[df['Segment'] == 'Recent Customers']['Country'].value_counts().index[:5])\n",
        "plt.title('Recent Customers')\n",
        "\n",
        "# Plotting Big Spenders\n",
        "plt.subplot(2, 3, 2)\n",
        "sns.countplot(x='Country', data=df[df['Segment'] == 'Big Spenders'], order=df[df['Segment'] == 'Big Spenders']['Country'].value_counts().index[:5])\n",
        "plt.title('Big Spenders')\n",
        "\n",
        "# Plotting Churn Risk Customers\n",
        "plt.subplot(2, 3, 3)\n",
        "sns.countplot(x='Country', data=df[df['Segment'] == 'Churn Risk Customers'], order=df[df['Segment'] == 'Churn Risk Customers']['Country'].value_counts().index[:5])\n",
        "plt.title('Churn Risk Customers')\n",
        "\n",
        "# Plotting Potential Loyal Customers\n",
        "plt.subplot(2, 3, 4)\n",
        "sns.countplot(x='Country', data=df[df['Segment'] == 'Potential Loyal Customers'], order=df[df['Segment'] == 'Potential Loyal Customers']['Country'].value_counts().index[:5])\n",
        "plt.title('Potential Loyal Customers')\n",
        "\n",
        "# Plotting High-Value Customers\n",
        "plt.subplot(2, 3, 5)\n",
        "sns.countplot(x='Country', data=df[df['Segment'] == 'High-Value Customers'], order=df[df['Segment'] == 'High-Value Customers']['Country'].value_counts().index[:5])\n",
        "plt.title('High-Value Customers')\n",
        "\n",
        "# Adjusting the layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# showing the plots\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wJzWfx78tkc"
      },
      "outputs": [],
      "source": [
        "# Set up the plotting environment\n",
        "plt.figure(figsize=(15, 12))\n",
        "\n",
        "# Plotting Recent Customers\n",
        "plt.subplot(3, 2, 1)\n",
        "recent_customers_top5 = df[df['Segment'] == 'Recent Customers']['Country'].value_counts().head(5)\n",
        "sns.barplot(x=recent_customers_top5.index, y=recent_customers_top5.values)\n",
        "plt.title('Recent Customers - Top 5 Countries')\n",
        "plt.xlabel('Country')\n",
        "plt.ylabel('Count')\n",
        "for i, value in enumerate(recent_customers_top5.values):\n",
        "    plt.text(i, value, str(value), ha='center', va='bottom')\n",
        "\n",
        "plt.subplot(3, 2, 2)\n",
        "recent_customers_least5 = df[df['Segment'] == 'Recent Customers']['Country'].value_counts().tail(5)\n",
        "sns.barplot(x=recent_customers_least5.index, y=recent_customers_least5.values)\n",
        "plt.title('Recent Customers - Least 5 Countries')\n",
        "plt.xlabel('Country')\n",
        "plt.ylabel('Count')\n",
        "for i, value in enumerate(recent_customers_least5.values):\n",
        "    plt.text(i, value, str(value), ha='center', va='bottom')\n",
        "\n",
        "\n",
        "# Plotting Big Spenders\n",
        "plt.subplot(3, 2, 3)\n",
        "big_spenders_top5 = df[df['Segment'] == 'Big Spenders']['Country'].value_counts().head(5)\n",
        "sns.barplot(x=big_spenders_top5.index, y=big_spenders_top5.values)\n",
        "plt.title('Big Spenders - Top 5 Countries')\n",
        "plt.xlabel('Country')\n",
        "plt.ylabel('Count')\n",
        "for i, value in enumerate(big_spenders_top5.values):\n",
        "    plt.text(i, value, str(value), ha='center', va='bottom')\n",
        "\n",
        "plt.subplot(3, 2, 4)\n",
        "big_spenders_least5 = df[df['Segment'] == 'Big Spenders']['Country'].value_counts().tail(5)\n",
        "sns.barplot(x=big_spenders_least5.index, y=big_spenders_least5.values)\n",
        "plt.title('Big Spenders - Least 5 Countries')\n",
        "plt.xlabel('Country')\n",
        "plt.ylabel('Count')\n",
        "for i, value in enumerate(big_spenders_least5.values):\n",
        "    plt.text(i, value, str(value), ha='center', va='bottom')\n",
        "\n",
        "# Plotting Churn Risk Customers\n",
        "plt.subplot(3, 2, 5)\n",
        "churn_risk_top5 = df[df['Segment'] == 'Churn Risk Customers']['Country'].value_counts().head(5)\n",
        "sns.barplot(x=churn_risk_top5.index, y=churn_risk_top5.values)\n",
        "plt.title('Churn Risk Customers - Top 5 Countries')\n",
        "plt.xlabel('Country')\n",
        "plt.ylabel('Count')\n",
        "for i, value in enumerate(churn_risk_top5.values):\n",
        "    plt.text(i, value, str(value), ha='center', va='bottom')\n",
        "\n",
        "plt.subplot(3, 2, 6)\n",
        "churn_risk_least5 = df[df['Segment'] == 'Churn Risk Customers']['Country'].value_counts().tail(5)\n",
        "sns.barplot(x=churn_risk_least5.index, y=churn_risk_least5.values)\n",
        "plt.title('Churn Risk Customers - Least 5 Countries')\n",
        "plt.xlabel('Country')\n",
        "plt.ylabel('Count')\n",
        "for i, value in enumerate(churn_risk_least5.values):\n",
        "    plt.text(i, value, str(value), ha='center', va='bottom')\n",
        "\n",
        "# Adjusting the layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# showing the plots\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I97MSfNsxeMC"
      },
      "outputs": [],
      "source": [
        "# Set up the plotting environment\n",
        "plt.figure(figsize=(15, 12))\n",
        "\n",
        "# Plotting Recent Customers\n",
        "plt.subplot(3, 2, 1)\n",
        "recent_customers_top5 = df[(df['Segment'] == 'Recent Customers') & (df['Country'] != 'United Kingdom')]['Country'].value_counts().head(5)\n",
        "sns.barplot(x=recent_customers_top5.index, y=recent_customers_top5.values)\n",
        "plt.title('Recent Customers - Top 5 Countries (excluding United Kingdom)')\n",
        "plt.xlabel('Country')\n",
        "plt.ylabel('Count')\n",
        "for i, value in enumerate(recent_customers_top5.values):\n",
        "    plt.text(i, value, str(value), ha='center', va='bottom')\n",
        "\n",
        "plt.subplot(3, 2, 2)\n",
        "recent_customers_least5 = df[df['Segment'] == 'Recent Customers']['Country'].value_counts().tail(5)\n",
        "sns.barplot(x=recent_customers_least5.index, y=recent_customers_least5.values)\n",
        "plt.title('Recent Customers - Least 5 Countries')\n",
        "plt.xlabel('Country')\n",
        "plt.ylabel('Count')\n",
        "for i, value in enumerate(recent_customers_least5.values):\n",
        "    plt.text(i, value, str(value), ha='center', va='bottom')\n",
        "\n",
        "# Plotting Big Spenders\n",
        "plt.subplot(3, 2, 3)\n",
        "big_spenders_top5 = df[(df['Segment'] == 'Big Spenders') & (df['Country'] != 'United Kingdom')]['Country'].value_counts().head(5)\n",
        "sns.barplot(x=big_spenders_top5.index, y=big_spenders_top5.values)\n",
        "plt.title('Big Spenders - Top 5 Countries (excluding United Kingdom)')\n",
        "plt.xlabel('Country')\n",
        "plt.ylabel('Count')\n",
        "for i, value in enumerate(big_spenders_top5.values):\n",
        "    plt.text(i, value, str(value), ha='center', va='bottom')\n",
        "\n",
        "plt.subplot(3, 2, 4)\n",
        "big_spenders_least5 = df[df['Segment'] == 'Big Spenders']['Country'].value_counts().tail(5)\n",
        "sns.barplot(x=big_spenders_least5.index, y=big_spenders_least5.values)\n",
        "plt.title('Big Spenders - Least 5 Countries')\n",
        "plt.xlabel('Country')\n",
        "plt.ylabel('Count')\n",
        "for i, value in enumerate(big_spenders_least5.values):\n",
        "    plt.text(i, value, str(value), ha='center', va='bottom')\n",
        "\n",
        "# Plotting Churn Risk Customers\n",
        "plt.subplot(3, 2, 5)\n",
        "churn_risk_top5 = df[(df['Segment'] == 'Churn Risk Customers') & (df['Country'] != 'United Kingdom')]['Country'].value_counts().head(5)\n",
        "sns.barplot(x=churn_risk_top5.index, y=churn_risk_top5.values)\n",
        "plt.title('Churn Risk Customers - Top 5 Countries (excluding United Kingdom)')\n",
        "plt.xlabel('Country')\n",
        "plt.ylabel('Count')\n",
        "for i, value in enumerate(churn_risk_top5.values):\n",
        "    plt.text(i, value, str(value), ha='center', va='bottom')\n",
        "\n",
        "plt.subplot(3, 2, 6)\n",
        "churn_risk_least5 = df[df['Segment'] == 'Churn Risk Customers']['Country'].value_counts().tail(5)\n",
        "sns.barplot(x=churn_risk_least5.index, y=churn_risk_least5.values)\n",
        "plt.title('Churn Risk Customers - Least 5 Countries')\n",
        "plt.xlabel('Country')\n",
        "plt.ylabel('Count')\n",
        "for i, value in enumerate(churn_risk_least5.values):\n",
        "    plt.text(i, value, str(value), ha='center', va='bottom')\n",
        "\n",
        "# Adjusting the layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# showing the plots\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JFKzom__BxF"
      },
      "source": [
        "**Recency:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrM4n6vO-GVU"
      },
      "outputs": [],
      "source": [
        "# we haveyou have a DataFrame named 'df' with a 'Recency' column and a 'Segment' column\n",
        "\n",
        "# Group by 'Segment' and Calculating the average recency\n",
        "average_recency = df.groupby('Segment')['Recency'].mean().reset_index()\n",
        "\n",
        "# Plot the average recency for each segment with numbers on top of the bars\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar(average_recency['Segment'], average_recency['Recency'], color='skyblue')\n",
        "plt.title('Average Recency for Each Segment')\n",
        "plt.xlabel('Segment')\n",
        "plt.ylabel('Average Recency')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "# Displaying the numerical values on top of the bars\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom', color='black')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dh9lcfRD_Fiv"
      },
      "outputs": [],
      "source": [
        "from prettytable import PrettyTable\n",
        "\n",
        "# we have you have a DataFrame named 'average_recency' with 'Segment' and 'Recency' columns\n",
        "table = PrettyTable()\n",
        "table.field_names = [\"Segment\", \"Average Recency\"]\n",
        "\n",
        "for index, row in average_recency.iterrows():\n",
        "    table.add_row([row['Segment'], round(row['Recency'], 2)])\n",
        "\n",
        "print(table)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZ8kw3SFAZVy"
      },
      "source": [
        "**Price Relation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zgmfAgMBAov"
      },
      "outputs": [],
      "source": [
        "# we have DataFrame with columns like 'CustomerID', 'UnitPrice', and 'Segment'\n",
        "# Replace 'Segment' with the actual column name where you have assigned customer segments\n",
        "\n",
        "# Calculating average price per customer\n",
        "avg_price_per_customer = df.groupby('CustomerID')['UnitPrice'].mean().reset_index()\n",
        "\n",
        "# Merge with the original DataFrame to get the 'Segment' information\n",
        "df_with_segments = pd.merge(avg_price_per_customer, df[['CustomerID', 'Segment']], on='CustomerID', how='left')\n",
        "\n",
        "# Plot a bar chart for average prices by customer segment\n",
        "plt.figure(figsize=(12, 6))\n",
        "ax = sns.barplot(x='Segment', y='UnitPrice', data=df_with_segments, ci=None, palette='viridis')\n",
        "\n",
        "# adding values on top of the bars\n",
        "for p in ax.patches:\n",
        "    ax.annotate(f'{p.get_height():.2f}', (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center', xytext=(0, 10), textcoords='offset points', fontsize=8, color='black')\n",
        "\n",
        "plt.title('Average Unit Price by Customer Segment')\n",
        "plt.xlabel('Customer Segment')\n",
        "plt.ylabel('Average Unit Price')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_wlzG9WCWMT"
      },
      "outputs": [],
      "source": [
        "# we have 'df' is we have DataFrame with columns like 'CustomerID', 'UnitPrice', and 'Segment'\n",
        "# Replace 'Segment' with the actual column name where you have assigned customer segments\n",
        "\n",
        "# Calculating average price per customer\n",
        "avg_price_per_customer = df.groupby('CustomerID')['UnitPrice'].mean().reset_index()\n",
        "\n",
        "# Merge with the original DataFrame to get the 'Segment' information\n",
        "df_with_segments = pd.merge(avg_price_per_customer, df[['CustomerID', 'Segment']], on='CustomerID', how='left')\n",
        "\n",
        "# Creatinga subplot with 1 row and 2 columns\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Plot the average prices by customer segment with switched axes\n",
        "ax1 = sns.barplot(x='UnitPrice', y='Segment', data=df_with_segments, ci=None, palette='viridis', ax=axes[0])\n",
        "for p in ax1.patches:\n",
        "    ax1.annotate(f'{p.get_width():.2f}', (p.get_width(), p.get_y() + p.get_height() / 2.), ha='left', va='center', xytext=(5, 0), textcoords='offset points', fontsize=8, color='black')\n",
        "ax1.set_title('Average Unit Price by Customer Segment')\n",
        "ax1.set_xlabel('Average Unit Price')\n",
        "ax1.set_ylabel('Customer Segment')\n",
        "\n",
        "# Plot the percentage of customers in each segment\n",
        "segment_percentage = df['Segment'].value_counts(normalize=True) * 100\n",
        "ax2 = segment_percentage.plot(kind='pie', autopct='%1.1f%%', colors=sns.color_palette('viridis'), ax=axes[1])\n",
        "ax2.set_title('Percentage of Customers in Each Segment')\n",
        "\n",
        "# Adjusting the layout\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-mj2S_RGAX8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "# Calculating average price per customer\n",
        "avg_price_per_customer = df.groupby('CustomerID')['UnitPrice'].mean().reset_index()\n",
        "\n",
        "# Merge with the original DataFrame to get the 'Segment' information\n",
        "df_with_segments = pd.merge(avg_price_per_customer, df[['CustomerID', 'Segment']], on='CustomerID', how='left')\n",
        "\n",
        "# Displaying the results in a table\n",
        "table = PrettyTable()\n",
        "table.field_names = ['CustomerID', 'Segment', 'Average Unit Price']\n",
        "\n",
        "for _, row in df_with_segments.iterrows():\n",
        "    table.add_row([row['CustomerID'], row['Segment'], f'{row[\"UnitPrice\"]:.2f}'])\n",
        "\n",
        "print(\"Average Unit Price by Customer Segment:\")\n",
        "print(table)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJFx53niB7xV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}